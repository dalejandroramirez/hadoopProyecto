{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PySpark**: The Apache Spark Python API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "This notebook shows how to connect Jupyter notebooks to a Spark cluster to process data using Spark Python API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The Spark Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Connection\n",
    "\n",
    "To connect to the Spark cluster, create a SparkSession object with the following params:\n",
    "\n",
    "+ **appName:** application name displayed at the [Spark Master Web UI](http://localhost:8080/);\n",
    "+ **master:** Spark Master URL, same used by Spark Workers;\n",
    "+ **spark.executor.memory:** must be less than or equals to docker compose SPARK_WORKER_MEMORY config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"pyspark-notebook\").master(\"spark://spark-master:7077\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More confs for SparkSession object in standalone mode can be added using the **config** method. Checkout the API docs [here](https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.SparkSession)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/pc/Documentos/henry/hadoopProyecto/pasos/Paso6/scripts/pyspark-ETL.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/pc/Documentos/henry/hadoopProyecto/pasos/Paso6/scripts/pyspark-ETL.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m venta \u001b[39m=\u001b[39m spark\u001b[39m.\u001b[39mread\u001b[39m.\u001b[39moption(\u001b[39m\"\u001b[39m\u001b[39mcompression.codec\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msnappy\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39moption(\u001b[39m\"\u001b[39m\u001b[39mmergeSchema\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtrue\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mparquet(\u001b[39m\"\u001b[39m\u001b[39mdata2/venta\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/15 17:12:04 WARN StandaloneAppClient$ClientEndpoint: Failed to connect to master spark-master:7077\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anon$1.run(StandaloneAppClient.scala:108)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.io.IOException: Failed to connect to spark-master:7077\n",
      "\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:294)\n",
      "\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:214)\n",
      "\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:226)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:204)\n",
      "\tat org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:202)\n",
      "\tat org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:198)\n",
      "\t... 4 more\n",
      "Caused by: java.net.UnknownHostException: spark-master\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:797)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1386)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1307)\n",
      "\tat java.base/java.net.InetAddress.getByName(InetAddress.java:1257)\n",
      "\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:156)\n",
      "\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:153)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:153)\n",
      "\tat io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:41)\n",
      "\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:61)\n",
      "\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:53)\n",
      "\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:55)\n",
      "\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:31)\n",
      "\tat io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:106)\n",
      "\tat io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:220)\n",
      "\tat io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:46)\n",
      "\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:189)\n",
      "\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:175)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:590)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:557)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:492)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:636)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:625)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:105)\n",
      "\tat io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:990)\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:516)\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:429)\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:486)\n",
      "\tat io.netty.util.concurrent.AbstractEventExecutor.runTask(AbstractEventExecutor.java:174)\n",
      "\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:167)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:470)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:569)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\t... 1 more\n",
      "23/10/15 17:12:24 WARN StandaloneSchedulerBackend: Application ID is not initialized yet.\n",
      "23/10/15 17:12:24 ERROR StandaloneSchedulerBackend: Application has been killed. Reason: All masters are unresponsive! Giving up.\n",
      "23/10/15 17:12:24 WARN StandaloneAppClient$ClientEndpoint: Drop UnregisterApplication(null) because has not yet connected to master\n",
      "23/10/15 17:12:29 ERROR AsyncEventQueue: Listener AppStatusListener threw an exception\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.status.AppStatusListener.onApplicationEnd(AppStatusListener.scala:193)\n",
      "\tat org.apache.spark.scheduler.SparkListenerBus.doPostEvent(SparkListenerBus.scala:57)\n",
      "\tat org.apache.spark.scheduler.SparkListenerBus.doPostEvent$(SparkListenerBus.scala:28)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)\n",
      "\tat org.apache.spark.util.ListenerBus.postToAll(ListenerBus.scala:117)\n",
      "\tat org.apache.spark.util.ListenerBus.postToAll$(ListenerBus.scala:101)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.super$postToAll(AsyncEventQueue.scala:105)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.$anonfun$dispatch$1(AsyncEventQueue.scala:105)\n",
      "\tat scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)\n",
      "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:100)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue$$anon$2.$anonfun$run$1(AsyncEventQueue.scala:96)\n",
      "\tat org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1356)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue$$anon$2.run(AsyncEventQueue.scala:96)\n",
      "23/10/15 17:12:30 ERROR SparkContext: Error initializing SparkContext.\n",
      "java.lang.IllegalArgumentException: requirement failed: Can only call getServletHandlers on a running MetricsSystem\n",
      "\tat scala.Predef$.require(Predef.scala:281)\n",
      "\tat org.apache.spark.metrics.MetricsSystem.getServletHandlers(MetricsSystem.scala:89)\n",
      "\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:676)\n",
      "\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:238)\n",
      "\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n",
      "\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n"
     ]
    }
   ],
   "source": [
    "venta = spark.read.option(\"compression.codec\", \"snappy\").option(\"mergeSchema\", \"true\").parquet(\"data2/venta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46645"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "venta.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(venta.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- idventa: integer (nullable = true)\n",
      " |-- fecha: date (nullable = true)\n",
      " |-- fecha_entrega: date (nullable = true)\n",
      " |-- idcanal: integer (nullable = true)\n",
      " |-- idcliente: integer (nullable = true)\n",
      " |-- idsucursal: integer (nullable = true)\n",
      " |-- idempleado: integer (nullable = true)\n",
      " |-- idproducto: integer (nullable = true)\n",
      " |-- precio: float (nullable = true)\n",
      " |-- cantidad: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "venta.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-------------+-------+---------+----------+----------+----------+------+--------+\n",
      "|idventa|     fecha|fecha_entrega|idcanal|idcliente|idsucursal|idempleado|idproducto|precio|cantidad|\n",
      "+-------+----------+-------------+-------+---------+----------+----------+----------+------+--------+\n",
      "|      1|2018-03-09|   2018-03-17|      3|      969|        13|      1674|     42817|813.12|       2|\n",
      "|      2|2018-12-28|   2018-12-29|      2|      884|        13|      1674|     42795|543.18|       3|\n",
      "|      3|2016-03-28|   2016-03-31|      2|     1722|        13|      1674|     42837|430.32|       1|\n",
      "|      4|2017-10-23|   2017-10-24|      3|     2876|        13|      1674|     42834|818.84|       2|\n",
      "|      5|2017-11-22|   2017-11-25|      2|      678|        13|      1674|     42825|554.18|       3|\n",
      "|      6|2018-01-24|   2018-01-25|      2|     3263|        13|      1674|     42852| 152.0|       1|\n",
      "|      7|2015-03-25|   2015-03-26|      3|     2983|        13|      1674|     42939|2915.0|       1|\n",
      "|      8|2017-07-10|   2017-07-18|      2|      201|        13|      1674|     42940|2162.0|       2|\n",
      "|      9|2018-04-03|   2018-04-06|      2|     1006|        13|      1674|     42905| 456.0|       3|\n",
      "|     10|2019-03-16|   2019-03-17|      1|     1003|        13|      1674|     42894| 515.0|       2|\n",
      "+-------+----------+-------------+-------+---------+----------+----------+----------+------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "venta.show(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate statistics\n",
    "ventas_out = venta.na.drop(subset=['precio','cantidad']).groupBy(\"idproducto\").agg(mean(venta.precio).alias(\"promedio\"), stddev(venta.precio).alias(\"stddev\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "ventas_out = ventas_out.withColumn(\"PrecioMaximo\", ventas_out.promedio + ventas_out.stddev * 3).withColumn(\"PrecioMinimo\", ventas_out.promedio - ventas_out.stddev * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+------------------+------------------+-------------------+\n",
      "|idproducto|          promedio|            stddev|      PrecioMaximo|       PrecioMinimo|\n",
      "+----------+------------------+------------------+------------------+-------------------+\n",
      "|     42834|1772.5477912454044| 8766.698479843624|28072.643230776277| -24527.54764828547|\n",
      "|     43010| 579.5276381909548|2715.9365607484365| 8727.337320436265| -7568.282044054355|\n",
      "|     42926| 173.2289156626506| 855.8609108933418| 2740.811648342676|-2394.3538170173747|\n",
      "|     42754| 3399.485294117647|16178.246644473787|51934.225227539006| -45135.25463930372|\n",
      "|     42942| 9817.857142857143| 43428.96544353547|140104.75347346353|-120469.03918774925|\n",
      "|     42817|2294.6944737346626|10853.233513624373|34854.395014607784|-30265.006067138456|\n",
      "|     43007| 883.8402366863905|  4370.23553541889| 13994.54684294306| -12226.86636957028|\n",
      "|     42988|2085.4874371859296| 9288.874866279935|29952.112036025737|-25781.137161653878|\n",
      "|     42780| 8983.607186832784| 44315.73955637865|141930.82585596872|-123963.61148230315|\n",
      "|     42783| 5468.261329034841|  26974.6927750322| 86392.33965413144| -75455.81699606177|\n",
      "+----------+------------------+------------------+------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ventas_out.show(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "ventas_out.write.option(\"compression.codec\", \"snappy\").option(\"mergeSchema\", \"true\").parquet(\"data2/venta_criterio_outliers\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "venta = venta.alias(\"v\").join(ventas_out.alias(\"o\"), venta['idproducto'] == ventas_out['idproducto']).select(\"v.idventa\",\"v.fecha\",\"v.fecha_entrega\",\"v.idcanal\",\"v.idcliente\",\"v.idsucursal\",\"v.idempleado\",\"v.idproducto\",\"v.precio\",\"v.cantidad\",\"o.promedio\",\"o.stddev\",\"o.PrecioMaximo\",\"o.PrecioMinimo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- idventa: integer (nullable = true)\n",
      " |-- fecha: date (nullable = true)\n",
      " |-- fecha_entrega: date (nullable = true)\n",
      " |-- idcanal: integer (nullable = true)\n",
      " |-- idcliente: integer (nullable = true)\n",
      " |-- idsucursal: integer (nullable = true)\n",
      " |-- idempleado: integer (nullable = true)\n",
      " |-- idproducto: integer (nullable = true)\n",
      " |-- precio: float (nullable = true)\n",
      " |-- cantidad: integer (nullable = true)\n",
      " |-- promedio: double (nullable = true)\n",
      " |-- stddev: double (nullable = true)\n",
      " |-- PrecioMaximo: double (nullable = true)\n",
      " |-- PrecioMinimo: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "venta.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[idventa: int, fecha: date, fecha_entrega: date, idcanal: int, idcliente: int, idsucursal: int, idempleado: int, idproducto: int, precio: float, cantidad: int, promedio: double, stddev: double, PrecioMaximo: float, PrecioMinimo: double]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "venta.withColumn(\"PrecioMaximo\",col(\"PrecioMaximo\").cast(\"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[idventa: int, fecha: date, fecha_entrega: date, idcanal: int, idcliente: int, idsucursal: int, idempleado: int, idproducto: int, precio: float, cantidad: int, promedio: double, stddev: double, PrecioMaximo: double, PrecioMinimo: float]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "venta.withColumn(\"PrecioMinimo\",col(\"PrecioMinimo\").cast(\"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detecta_outlier(valor, maximo, minimo):\n",
    "    return (valor < minimo) or (valor > maximo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "udf_detecta_outlier = udf(lambda valor, MaxLimit, MinLimit: detecta_outlier(valor, MaxLimit, MinLimit), BooleanType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "46645"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "venta.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "venta = venta.na.drop(subset=['precio','cantidad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "44845"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "venta.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "venta = venta.withColumn(\"esOutlier\", udf_detecta_outlier(venta.precio, venta.PrecioMaximo, venta.PrecioMinimo)).filter(\"NOT esOutlier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-------------+-------+---------+----------+----------+----------+------+--------+------------------+------------------+------------------+-------------------+---------+\n",
      "|idventa|     fecha|fecha_entrega|idcanal|idcliente|idsucursal|idempleado|idproducto|precio|cantidad|          promedio|            stddev|      PrecioMaximo|       PrecioMinimo|esOutlier|\n",
      "+-------+----------+-------------+-------+---------+----------+----------+----------+------+--------+------------------+------------------+------------------+-------------------+---------+\n",
      "|      1|2018-03-09|   2018-03-17|      3|      969|        13|      1674|     42817|813.12|       2|2294.6944737346626|10853.233513624373|34854.395014607784|-30265.006067138456|    false|\n",
      "|      2|2018-12-28|   2018-12-29|      2|      884|        13|      1674|     42795|543.18|       3| 2491.543036419412|10085.326471187416| 32747.52244998166| -27764.43637714284|    false|\n",
      "|      3|2016-03-28|   2016-03-31|      2|     1722|        13|      1674|     42837|430.32|       1|1117.4438781738281| 5381.093790556302|17260.725249842733|-15025.837493495079|    false|\n",
      "|      4|2017-10-23|   2017-10-24|      3|     2876|        13|      1674|     42834|818.84|       2|1772.5477912454044| 8766.698479843624|28072.643230776277| -24527.54764828547|    false|\n",
      "|      5|2017-11-22|   2017-11-25|      2|      678|        13|      1674|     42825|554.18|       3| 554.1799926757812|               0.0| 554.1799926757812|  554.1799926757812|    false|\n",
      "|      6|2018-01-24|   2018-01-25|      2|     3263|        13|      1674|     42852| 152.0|       1|481.51824817518246|2210.3552086851587| 7112.583874230659| -6149.547377880293|    false|\n",
      "|      7|2015-03-25|   2015-03-26|      3|     2983|        13|      1674|     42939|2915.0|       1| 8464.711538461539| 39760.51016759243|127746.24204123882|-110816.81896431575|    false|\n",
      "|      8|2017-07-10|   2017-07-18|      2|      201|        13|      1674|     42940|2162.0|       2| 4694.994082840237|23214.862967016314| 74339.58298388917|-64949.594818208694|    false|\n",
      "|      9|2018-04-03|   2018-04-06|      2|     1006|        13|      1674|     42905| 456.0|       3| 2068.285714285714| 8402.727764360237|27276.469007366428|   -23139.897578795|    false|\n",
      "|     10|2019-03-16|   2019-03-17|      1|     1003|        13|      1674|     42894| 515.0|       2|            922.88| 4560.237033313071|14603.591099939213|-12757.831099939214|    false|\n",
      "+-------+----------+-------------+-------+---------+----------+----------+----------+------+--------+------------------+------------------+------------------+-------------------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "venta.show(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "venta = venta.select([\"idventa\",\"fecha\",\"fecha_entrega\",\"idcanal\",\"idcliente\",\"idsucursal\",\"idempleado\",\"idproducto\",\"precio\",\"cantidad\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "venta.write.option(\"compression.codec\", \"snappy\").option(\"mergeSchema\", \"true\").parquet(\"data2/venta_sin_outliers\", mode=\"overwrite\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
